================================================================================
WORKFLOW: Route User Requests to Specialized Agents with GPT-4o Mini
================================================================================

üìã BASIC INFORMATION
------------------------------
ID: 4150
Name: Route User Requests to Specialized Agents with GPT-4o Mini
Total Views: 234
Created At: 2025-05-17T14:13:40.939Z
Purchase URL: None

üë§ AUTHOR INFORMATION
------------------------------
Name: Dhrumil Patel
Username: itechdp
Verified: ‚úÖ Yes
Bio: üöÄ Automation Enthusiast | n8n Creator | SaaS & AI Innovator. I'm Dhrumil Patel, founder of SentIIMenta AI. I build smart solutions using n8n to automate workflows, connect data, and boost efficiency. Passionate about AI, SaaS, and no-code tools. Let‚Äôs simplify work and create impact together!
üåê https://sentiimenta-ai.com | üì© founder@sentiimenta-ai.com
Links: https://sentiimenta-ai.com

üìù DESCRIPTION
------------------------------
This n8n workflow template is designed to route user input to specialized agents (like a Reminder Agent, Email Agent, etc.) using a structured output from a language model. Here's a complete description of what it does and how each part works:

üîÅ Workflow Purpose:

This template receives a user's request via Webhook, processes it using an LLM, extracts structured data like the agent name and user query, and routes the input to the appropriate sub-workflow (agent) based on the specified agent type.

üß© Workflow Breakdown:

1. Webhook (Trigger)

Node: Webhook
Purpose: Accepts a POST request from any frontend or API source. It contains the raw user input.

2. GPT Model (LLM Inference)

Node: GPT 4o Mini
Purpose: Interprets the user input and determines:

  Which agent should handle it (e.g., "Reminder Agent", "Email Agent", etc.)
  The actual user request (in structured format)

3. Auto-Fixing Output Parser

Node: Auto-fixing Output Parser
Purpose: Ensures that the output from the LLM matches the expected structure. If there's a mismatch, it automatically corrects it using a re-prompt.

4. Structured Output Parser

Node: Structured Output Parser
Purpose: Converts the language model's response into a strict JSON structure with keys like:

  "Agent Name"
  "user input"
  "sessionID"

5. Agent Router

Node: Switch ("Agent Route")
Purpose: Based on "Agent Name", it routes the input to one of the following sub-workflows:

  üìÖ Reminder Agent
  üìß Email Agent
  üßæ Document Agent
  ü§ù Meeting Agent

6. Sub-Workflow Call (Execute Workflow)

Each agent is implemented as a separate n8n workflow:

The input is forwarded to the selected agent.
For example, if "Agent Name" is "Reminder Agent", the workflow "Reminder Agent" is called with "user input".

7. Webhook Response

After the sub-agent workflow finishes, a Respond to Webhook node sends the output back as an HTTP response.

‚úÖ Key Features:

Fully modular and extensible
LLM-driven routing using OpenRouter GPT-4o
Auto-corrects structured output errors
Clean separation of concerns (agent logic is decoupled in sub-workflows)
Easily add more agents by updating the switch logic

üì¶ Use Case Examples:

User says: ‚ÄúRemind me to call my mom tomorrow.‚Äù
  ‚Üí Routed to Reminder Agent

User says: ‚ÄúSend an email to the HR team.‚Äù
  ‚Üí Routed to Email Agent

User says: ‚ÄúSchedule a meeting with John next week.‚Äù
  ‚Üí Routed to Meeting Agent

üîß NODES USED
------------------------------
‚Ä¢ AI Agent - Categories: AI, Langchain
‚Ä¢ Auto-fixing Output Parser - Categories: AI, Langchain
‚Ä¢ Structured Output Parser - Categories: AI, Langchain
‚Ä¢ Postgres Chat Memory - Categories: AI, Langchain
‚Ä¢ OpenRouter Chat Model - Categories: AI, Langchain

Total Nodes: 5

üìä RAW DATA (JSON)
------------------------------
{
  "id": 4150,
  "name": "Route User Requests to Specialized Agents with GPT-4o Mini",
  "totalViews": 234,
  "purchaseUrl": null,
  "user": {
    "id": 94592,
    "name": "Dhrumil Patel",
    "username": "itechdp",
    "bio": "üöÄ Automation Enthusiast | n8n Creator | SaaS & AI Innovator. I'm Dhrumil Patel, founder of SentIIMenta AI. I build smart solutions using n8n to automate workflows, connect data, and boost efficiency. Passionate about AI, SaaS, and no-code tools. Let‚Äôs simplify work and create impact together!\nüåê https://sentiimenta-ai.com | üì© founder@sentiimenta-ai.com",
    "verified": true,
    "links": "[\"https://sentiimenta-ai.com\"]",
    "avatar": "https://gravatar.com/avatar/50caca5ec3d609653f1b77216e53528b6e8412467a86c526dd0821c86253dbc1?r=pg&d=retro&size=200"
  },
  "description": "This n8n workflow template is designed to route user input to specialized agents (like a Reminder Agent, Email Agent, etc.) using a structured output from a language model. Here's a complete description of what it does and how each part works:\n\nüîÅ Workflow Purpose:\n\nThis template receives a user's request via Webhook, processes it using an LLM, extracts structured data like the agent name and user query, and routes the input to the appropriate sub-workflow (agent) based on the specified agent type.\n\nüß© Workflow Breakdown:\n\n1. Webhook (Trigger)\n\nNode: Webhook\nPurpose: Accepts a POST request from any frontend or API source. It contains the raw user input.\n\n2. GPT Model (LLM Inference)\n\nNode: GPT 4o Mini\nPurpose: Interprets the user input and determines:\n\n  Which agent should handle it (e.g., \"Reminder Agent\", \"Email Agent\", etc.)\n  The actual user request (in structured format)\n\n3. Auto-Fixing Output Parser\n\nNode: Auto-fixing Output Parser\nPurpose: Ensures that the output from the LLM matches the expected structure. If there's a mismatch, it automatically corrects it using a re-prompt.\n\n4. Structured Output Parser\n\nNode: Structured Output Parser\nPurpose: Converts the language model's response into a strict JSON structure with keys like:\n\n  \"Agent Name\"\n  \"user input\"\n  \"sessionID\"\n\n5. Agent Router\n\nNode: Switch (\"Agent Route\")\nPurpose: Based on \"Agent Name\", it routes the input to one of the following sub-workflows:\n\n  üìÖ Reminder Agent\n  üìß Email Agent\n  üßæ Document Agent\n  ü§ù Meeting Agent\n\n6. Sub-Workflow Call (Execute Workflow)\n\nEach agent is implemented as a separate n8n workflow:\n\nThe input is forwarded to the selected agent.\nFor example, if \"Agent Name\" is \"Reminder Agent\", the workflow \"Reminder Agent\" is called with \"user input\".\n\n7. Webhook Response\n\nAfter the sub-agent workflow finishes, a Respond to Webhook node sends the output back as an HTTP response.\n\n‚úÖ Key Features:\n\nFully modular and extensible\nLLM-driven routing using OpenRouter GPT-4o\nAuto-corrects structured output errors\nClean separation of concerns (agent logic is decoupled in sub-workflows)\nEasily add more agents by updating the switch logic\n\nüì¶ Use Case Examples:\n\nUser says: ‚ÄúRemind me to call my mom tomorrow.‚Äù\n  ‚Üí Routed to Reminder Agent\n\nUser says: ‚ÄúSend an email to the HR team.‚Äù\n  ‚Üí Routed to Email Agent\n\nUser says: ‚ÄúSchedule a meeting with John next week.‚Äù\n  ‚Üí Routed to Meeting Agent\n\n",
  "createdAt": "2025-05-17T14:13:40.939Z",
  "nodes": [
    {
      "id": 1119,
      "icon": "fa:robot",
      "name": "@n8n/n8n-nodes-langchain.agent",
      "codex": {
        "data": {
          "alias": [
            "LangChain",
            "Chat",
            "Conversational",
            "Plan and Execute",
            "ReAct",
            "Tools"
          ],
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Agents",
              "Root Nodes"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "AI Agent",
        "color": "#404040"
      },
      "iconData": {
        "icon": "robot",
        "type": "icon"
      },
      "displayName": "AI Agent",
      "typeVersion": 2,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1175,
      "icon": "fa:tools",
      "name": "@n8n/n8n-nodes-langchain.outputParserAutofixing",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparserautofixing/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Output Parsers"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Auto-fixing Output Parser"
      },
      "iconData": {
        "icon": "tools",
        "type": "icon"
      },
      "displayName": "Auto-fixing Output Parser",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1179,
      "icon": "fa:code",
      "name": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "codex": {
        "data": {
          "alias": [
            "json",
            "zod"
          ],
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparserstructured/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Output Parsers"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Structured Output Parser"
      },
      "iconData": {
        "icon": "code",
        "type": "icon"
      },
      "displayName": "Structured Output Parser",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1267,
      "icon": "file:postgres.svg",
      "name": "@n8n/n8n-nodes-langchain.memoryPostgresChat",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorypostgreschat/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Memory"
            ],
            "Memory": [
              "Other memories"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Postgres Chat Memory"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" fill="#fff" fill-rule="evenodd" stroke="#000" stroke-linecap="round" stroke-linejoin="round" viewBox="0 0 79 81"><use xlink:href="#a" x=".5" y=".5"/><symbol id="a" overflow="visible"><g fill-rule="nonzero" stroke="none"><path fill="#000" d="M77.391 47.922c-.466-1.412-1.688-2.396-3.268-2.632-.745-.111-1.598-.064-2.608.144-1.76.363-3.065.501-4.018.528 3.596-6.072 6.521-12.997 8.204-19.515 2.722-10.54 1.268-15.341-.432-17.513C70.77 3.185 64.206.097 56.287.002c-4.224-.052-7.933.782-9.867 1.382a37 37 0 0 0-5.77-.528c-3.809-.061-7.174.77-10.05 2.476a46 46 0 0 0-7.098-1.782C16.561.411 10.968 1.299 6.876 4.19 1.922 7.689-.375 13.77.05 22.262c.135 2.696 1.643 10.9 4.018 18.68 1.365 4.472 2.82 8.185 4.326 11.038 2.135 4.046 4.419 6.428 6.984 7.284 1.438.479 4.049.814 6.797-1.473a6 6 0 0 0 1.429 1.23c.783.494 1.74.897 2.696 1.136 3.446.862 6.674.646 9.427-.561l.041 1.362.06 1.899c.163 4.064.44 7.223 1.259 9.434.045.122.105.307.169.503.409 1.251 1.092 3.346 2.83 4.987 1.8 1.699 3.978 2.22 5.972 2.22 1 0 1.955-.131 2.792-.311 2.984-.639 6.373-1.614 8.824-5.104 2.318-3.3 3.444-8.27 3.648-16.101l.074-.634.048-.414.546.048.141.01c3.039.138 6.755-.506 9.037-1.566 1.803-.837 7.582-3.888 6.221-8.007"/><path fill="#336791" d="M72.195 48.723c-9.036 1.864-9.657-1.195-9.657-1.195 9.541-14.157 13.529-32.127 10.087-36.525C63.235-.994 46.981 4.68 46.71 4.827l-.087.016c-1.785-.371-3.783-.591-6.029-.628-4.089-.067-7.19 1.072-9.544 2.857 0 0-28.995-11.945-27.647 15.023.287 5.737 8.223 43.41 17.689 32.031 3.46-4.161 6.803-7.679 6.803-7.679 1.66 1.103 3.648 1.666 5.732 1.463l.162-.137a6.3 6.3 0 0 0 .065 1.62c-2.439 2.725-1.722 3.203-6.597 4.206-4.933 1.017-2.035 2.826-.143 3.299 2.294.574 7.6 1.386 11.185-3.633l-.143.573c.956.765 1.626 4.978 1.514 8.797s-.188 6.441.565 8.489 1.503 6.656 7.912 5.282c5.355-1.148 8.13-4.121 8.516-9.081.274-3.526.894-3.005.933-6.158l.497-1.493c.573-4.78.091-6.322 3.39-5.605l.802.07c2.428.11 5.606-.391 7.471-1.257 4.016-1.864 6.398-4.976 2.438-4.158"/><path d="M32.747 24.66c-.814-.113-1.552-.008-1.925.274a.7.7 0 0 0-.292.47c-.047.336.188.707.333.898.409.542 1.006.915 1.598.997a2 2 0 0 0 .256.018c.986 0 1.883-.768 1.962-1.335.099-.71-.932-1.183-1.931-1.322m26.975.022c-.078-.556-1.068-.715-2.007-.584s-1.848.554-1.772 1.112c.061.434.844 1.174 1.771 1.174q.117 0 .237-.016c.619-.086 1.073-.479 1.288-.705.329-.345.518-.73.484-.98m15.477 23.828c-.345-1.042-1.453-1.377-3.296-.997-5.471 1.129-7.43.347-8.073-.127 4.252-6.478 7.75-14.308 9.637-21.614.894-3.461 1.388-6.675 1.428-9.294.045-2.876-.445-4.988-1.455-6.279-4.072-5.203-10.048-7.994-17.283-8.07-4.973-.056-9.175 1.217-9.99 1.575a25 25 0 0 0-5.622-.722c-3.734-.06-6.961.834-9.633 2.655a43 43 0 0 0-7.828-2.052c-6.342-1.021-11.381-.248-14.978 2.3-4.291 3.04-6.272 8.475-5.888 16.152.129 2.583 1.601 10.529 3.923 18.139 3.057 10.016 6.38 15.686 9.877 16.852a4.4 4.4 0 0 0 1.402.232c1.276 0 2.839-.575 4.466-2.531a161 161 0 0 1 6.156-6.966 9.9 9.9 0 0 0 4.429 1.191l.01.121c-.31.368-.564.69-.781.965-1.07 1.358-1.293 1.641-4.738 2.351-.98.202-3.582.738-3.62 2.563-.041 1.993 3.076 2.83 3.431 2.919 1.238.31 2.43.463 3.568.463 2.766 0 5.2-.909 7.145-2.668-.06 7.106.236 14.107 1.089 16.241.699 1.746 2.406 6.014 7.798 6.014.791 0 1.662-.092 2.62-.297 5.627-1.207 8.071-3.694 9.016-9.177.506-2.93 1.374-9.928 1.782-13.682.862.269 1.971.392 3.17.392 2.501 0 5.387-.531 7.197-1.372 2.033-.944 5.702-3.261 5.037-5.274zM61.8 23.147c-.019 1.108-.171 2.114-.333 3.164-.174 1.129-.354 2.297-.399 3.715-.045 1.379.128 2.814.294 4.2.337 2.801.682 5.685-.655 8.531a11 11 0 0 1-.592-1.218c-.166-.403-.527-1.05-1.027-1.946-1.944-3.487-6.497-11.652-4.167-14.984.694-.992 2.456-2.011 6.879-1.463zM56.439 4.374c6.482.143 11.609 2.568 15.24 7.207 2.784 3.558-.282 19.749-9.158 33.716l-.269-.339-.112-.14c2.294-3.788 1.845-7.536 1.446-10.859-.164-1.364-.319-2.652-.28-3.861.041-1.283.21-2.382.374-3.446.202-1.311.407-2.667.35-4.265a1.8 1.8 0 0 0 .037-.601c-.144-1.533-1.894-6.12-5.462-10.273-1.951-2.271-4.797-4.813-8.682-6.527a29.3 29.3 0 0 1 6.515-.612zM20.167 53.298c-1.793 2.155-3.031 1.742-3.438 1.607-2.653-.885-5.73-6.491-8.444-15.382-2.348-7.693-3.72-15.428-3.829-17.597-.343-6.86 1.32-11.641 4.943-14.21 5.896-4.181 15.589-1.679 19.484-.409l-.17.163c-6.391 6.455-6.24 17.483-6.224 18.157a22 22 0 0 0 .051 1.135c.11 1.855.315 5.307-.232 9.217-.508 3.633.612 7.189 3.072 9.756q.383.398.795.75a164 164 0 0 0-6.008 6.814zm6.83-9.113c-1.983-2.069-2.884-4.947-2.471-7.896.577-4.13.364-7.727.25-9.659l-.039-.694c.934-.828 5.261-3.146 8.346-2.439 1.408.323 2.266 1.281 2.623 2.931 1.846 8.539.244 12.098-1.043 14.957-.265.589-.516 1.146-.73 1.722l-.166.445c-.42 1.126-.811 2.173-1.053 3.167-2.108-.006-4.159-.907-5.718-2.534zm.324 11.516a5 5 0 0 1-1.494-.642c.271-.128.754-.301 1.591-.474 4.052-.834 4.678-1.423 6.045-3.158.313-.398.669-.849 1.16-1.398.733-.821 1.068-.682 1.676-.43.493.204.972.821 1.167 1.501.092.321.195.93-.143 1.404-2.855 3.997-7.015 3.946-10.003 3.198zm21.207 19.735c-4.957 1.062-6.713-1.467-7.869-4.359-.747-1.867-1.113-10.285-.853-19.582a1.1 1.1 0 0 0-.048-.356 5 5 0 0 0-.139-.657c-.387-1.353-1.331-2.484-2.462-2.953-.45-.186-1.275-.528-2.267-.274.212-.871.578-1.855.976-2.921l.167-.448c.188-.505.423-1.029.673-1.583 1.347-2.992 3.192-7.091 1.19-16.35-.75-3.468-3.254-5.161-7.05-4.768-2.276.235-4.358 1.154-5.396 1.68q-.334.169-.618.329c.29-3.494 1.385-10.024 5.481-14.156 2.579-2.601 6.014-3.886 10.199-3.817 8.246.135 13.534 4.367 16.518 7.893 2.571 3.039 3.964 6.1 4.52 7.751-4.179-.425-7.022.4-8.463 2.46-3.135 4.481 1.715 13.178 4.046 17.358.427.766.796 1.428.912 1.709.759 1.839 1.742 3.067 2.459 3.964.22.275.433.541.596.774-1.266.365-3.539 1.208-3.332 5.422-.167 2.115-1.356 12.016-1.959 15.514-.797 4.621-2.497 6.343-7.279 7.368zm20.693-23.68c-1.294.601-3.46 1.052-5.518 1.148-2.273.107-3.43-.255-3.702-.477-.128-2.626.85-2.901 1.884-3.191.163-.046.321-.09.474-.144a4 4 0 0 0 .313.23c1.827 1.206 5.085 1.336 9.685.386l.05-.01c-.62.58-1.682 1.359-3.187 2.058z"/></g></symbol></svg>"
      },
      "displayName": "Postgres Chat Memory",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1281,
      "icon": "file:openrouter.svg",
      "name": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenrouter/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Language Models",
              "Root Nodes"
            ],
            "Language Models": [
              "Chat Models (Recommended)"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "OpenRouter Chat Model"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,PHN2ZyBmaWxsPSIjOTRBM0I4IiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIHdpZHRoPSI0MCIgaGVpZ2h0PSI0MCIgdmlld0JveD0iMCAwIDI0IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjx0aXRsZT5PcGVuUm91dGVyPC90aXRsZT48cGF0aCBkPSJNMTYuODA0IDEuOTU3bDcuMjIgNC4xMDV2LjA4N0wxNi43MyAxMC4yMWwuMDE3LTIuMTE3LS44MjEtLjAzYy0xLjA1OS0uMDI4LTEuNjExLjAwMi0yLjI2OC4xMS0xLjA2NC4xNzUtMi4wMzguNTc3LTMuMTQ3IDEuMzUyTDguMzQ1IDExLjAzYy0uMjg0LjE5NS0uNDk1LjMzNi0uNjguNDU1bC0uNTE1LjMyMi0uMzk3LjIzNC4zODUuMjMuNTMuMzM4Yy40NzYuMzE0IDEuMTcuNzk2IDIuNzAxIDEuODY2IDEuMTEuNzc1IDIuMDgzIDEuMTc3IDMuMTQ3IDEuMzUybC4zLjA0NWMuNjk0LjA5MSAxLjM3NS4wOTQgMi44MjUuMDMzbC4wMjItMi4xNTkgNy4yMiA0LjEwNXYuMDg3TDE2LjU4OSAyMmwuMDE0LTEuODYyLS42MzUuMDIyYy0xLjM4Ni4wNDItMi4xMzcuMDAyLTMuMTM4LS4xNjItMS42OTQtLjI4LTMuMjYtLjkyNi00Ljg4MS0yLjA1OWwtMi4xNTgtMS41YTIxLjk5NyAyMS45OTcgMCAwMC0uNzU1LS40OThsLS40NjctLjI4YTU1LjkyNyA1NS45MjcgMCAwMC0uNzYtLjQzQzIuOTA4IDE0LjczLjU2MyAxNC4xMTYgMCAxNC4xMTZWOS44ODhsLjE0LjAwNGMuNTY0LS4wMDcgMi45MS0uNjIyIDMuODA5LTEuMTI0bDEuMDE2LS41OC40MzgtLjI3NGMuNDI4LS4yOCAxLjA3Mi0uNzI2IDIuNjg2LTEuODUzIDEuNjIxLTEuMTMzIDMuMTg2LTEuNzggNC44ODEtMi4wNTkgMS4xNTItLjE5IDEuOTc0LS4yMTMgMy44MTQtLjEzOGwuMDItMS45MDd6Ij48L3BhdGg+PC9zdmc+Cg=="
      },
      "displayName": "OpenRouter Chat Model",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    }
  ]
}